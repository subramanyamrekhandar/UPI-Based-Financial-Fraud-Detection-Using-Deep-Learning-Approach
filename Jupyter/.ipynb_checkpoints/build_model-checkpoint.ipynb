{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE TRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../dataset/train_dataset.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_month</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>category</th>\n",
       "      <th>card_number</th>\n",
       "      <th>age</th>\n",
       "      <th>trans_amount</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>6.300000e+11</td>\n",
       "      <td>54</td>\n",
       "      <td>66.21</td>\n",
       "      <td>22</td>\n",
       "      <td>49879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>3.540000e+15</td>\n",
       "      <td>15</td>\n",
       "      <td>55.81</td>\n",
       "      <td>14</td>\n",
       "      <td>62668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>5.020000e+11</td>\n",
       "      <td>60</td>\n",
       "      <td>8.68</td>\n",
       "      <td>4</td>\n",
       "      <td>96037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>3.530000e+15</td>\n",
       "      <td>44</td>\n",
       "      <td>89.52</td>\n",
       "      <td>40</td>\n",
       "      <td>29911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>2.350000e+15</td>\n",
       "      <td>72</td>\n",
       "      <td>1.90</td>\n",
       "      <td>38</td>\n",
       "      <td>16421</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trans_hour  trans_day  trans_month  trans_year  category   card_number  \\\n",
       "0           0          1            1        2022        12  6.300000e+11   \n",
       "1           1          1            1        2022         3  3.540000e+15   \n",
       "2           3          1            1        2022         8  5.020000e+11   \n",
       "3           6          1            1        2022         4  3.530000e+15   \n",
       "4           6          1            1        2022         0  2.350000e+15   \n",
       "\n",
       "   age  trans_amount  state    zip  fraud_risk  \n",
       "0   54         66.21     22  49879           0  \n",
       "1   15         55.81     14  62668           0  \n",
       "2   60          8.68      4  96037           0  \n",
       "3   44         89.52     40  29911           0  \n",
       "4   72          1.90     38  16421           0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[ : , : 10].values\n",
    "y = dataset.iloc[ : , 10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10210, 10)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1802, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = np.count_nonzero(y_train == 1)\n",
    "valid = np.count_nonzero(y_train == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud cases in training data = 5106\n",
      "Valid cases in training data = 5104\n"
     ]
    }
   ],
   "source": [
    "print('Fraud cases in training data =', fraud)\n",
    "print('Valid cases in training data =', valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66337259,  1.24104545,  0.45653094,  0.37826057,  0.83408097,\n",
       "        -0.30554032,  2.3966382 , -0.73068363,  0.0181697 , -0.77660466],\n",
       "       [-1.6023747 , -0.07304053, -0.90455674,  0.37826057, -1.22335066,\n",
       "        -0.30836573,  0.74498916, -0.74861649,  0.64443135,  0.93890762],\n",
       "       [-1.12537527,  0.1459738 ,  0.45653094,  0.37826057,  0.57690202,\n",
       "        -0.30362247,  1.18542891, -0.79511806,  0.78360061, -1.2179066 ],\n",
       "       [-1.6023747 , -0.29205486, -0.36012167,  0.37826057, -0.70899275,\n",
       "        -0.30397763,  1.46070375, -0.51118115, -1.58227676,  1.76478537],\n",
       "       [-0.7676257 , -0.29205486, -1.44899181,  0.37826057, -0.70899275,\n",
       "        -0.30836532, -0.08083536,  0.02559291,  0.78360061, -1.18526965]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[ : 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02112216, -0.51106919,  1.27318354,  0.37826057,  1.34843888,\n",
       "         3.15638262,  0.35960438,  1.60624238,  0.64443135,  0.91726066],\n",
       "       [-0.05212655,  0.58400246,  0.1843134 ,  0.37826057,  0.83408097,\n",
       "        -0.30822372, -0.08083536, -0.65192446,  0.29650821, -1.52769864],\n",
       "       [ 1.14037202,  1.56956694,  0.72874847,  0.37826057,  1.09125992,\n",
       "        -0.30560345,  1.29553884,  1.71351642,  1.13152375,  1.07356281],\n",
       "       [ 1.02112216, -0.73008352,  0.1843134 ,  0.37826057,  1.09125992,\n",
       "        -0.30500363,  1.51575871,  1.6205402 ,  0.15733896,  0.77172649],\n",
       "       [-1.6023747 , -0.07304053, -0.08790413,  0.37826057,  1.34843888,\n",
       "        -0.30819767,  0.80004413, -0.06571388, -0.60809196,  0.84854544]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[ : 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression(random_state = 0)\n",
    "LR_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lr = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8485016648168702\n"
     ]
    }
   ],
   "source": [
    "print(acc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NEAREST NEIGHBORS (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN_model = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "KNN_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KNN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_knn = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8657047724750278\n"
     ]
    }
   ],
   "source": [
    "print(acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPPORT VECTOR MACHINE (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM_model = SVC(kernel = 'linear', random_state = 0)\n",
    "SVM_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = SVM_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_svm = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8479467258601554\n"
     ]
    }
   ],
   "source": [
    "print(acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAIVE BAYES (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_nb = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8496115427302997\n"
     ]
    }
   ],
   "source": [
    "print(acc_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECISION TREE (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "DT_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_dt = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967258601553829\n"
     ]
    }
   ],
   "source": [
    "print(acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF_model = RandomForestClassifier()\n",
    "RF_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = RF_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9728079911209767\n"
     ]
    }
   ],
   "source": [
    "print(acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVOLUTIONAL NEURAL NETWORK (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.add(tf.keras.layers.Dense(64, input_dim = 10, activation = 'relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "CNN_model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.4073 - accuracy: 0.8225\n",
      "Epoch 2/200\n",
      "320/320 [==============================] - 0s 818us/step - loss: 0.3187 - accuracy: 0.8531\n",
      "Epoch 3/200\n",
      "320/320 [==============================] - 0s 781us/step - loss: 0.3038 - accuracy: 0.8595\n",
      "Epoch 4/200\n",
      "320/320 [==============================] - 0s 771us/step - loss: 0.2978 - accuracy: 0.8643\n",
      "Epoch 5/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.2905 - accuracy: 0.8648\n",
      "Epoch 6/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.2838 - accuracy: 0.8700\n",
      "Epoch 7/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.2786 - accuracy: 0.8753\n",
      "Epoch 8/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.2716 - accuracy: 0.8777\n",
      "Epoch 9/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.2639 - accuracy: 0.8830\n",
      "Epoch 10/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.2570 - accuracy: 0.8881\n",
      "Epoch 11/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.2479 - accuracy: 0.8921\n",
      "Epoch 12/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.2392 - accuracy: 0.8985\n",
      "Epoch 13/200\n",
      "320/320 [==============================] - 0s 768us/step - loss: 0.2308 - accuracy: 0.9023\n",
      "Epoch 14/200\n",
      "320/320 [==============================] - 0s 778us/step - loss: 0.2155 - accuracy: 0.9133\n",
      "Epoch 15/200\n",
      "320/320 [==============================] - 0s 766us/step - loss: 0.2067 - accuracy: 0.9192\n",
      "Epoch 16/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.1957 - accuracy: 0.9225\n",
      "Epoch 17/200\n",
      "320/320 [==============================] - 0s 759us/step - loss: 0.1866 - accuracy: 0.9262\n",
      "Epoch 18/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.1795 - accuracy: 0.9281\n",
      "Epoch 19/200\n",
      "320/320 [==============================] - 0s 771us/step - loss: 0.1697 - accuracy: 0.9364\n",
      "Epoch 20/200\n",
      "320/320 [==============================] - 0s 759us/step - loss: 0.1678 - accuracy: 0.9345\n",
      "Epoch 21/200\n",
      "320/320 [==============================] - 0s 763us/step - loss: 0.1596 - accuracy: 0.9378\n",
      "Epoch 22/200\n",
      "320/320 [==============================] - 0s 778us/step - loss: 0.1568 - accuracy: 0.9395\n",
      "Epoch 23/200\n",
      "320/320 [==============================] - 0s 768us/step - loss: 0.1521 - accuracy: 0.9401\n",
      "Epoch 24/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.1473 - accuracy: 0.9446\n",
      "Epoch 25/200\n",
      "320/320 [==============================] - 0s 753us/step - loss: 0.1456 - accuracy: 0.9425\n",
      "Epoch 26/200\n",
      "320/320 [==============================] - 0s 834us/step - loss: 0.1409 - accuracy: 0.9458\n",
      "Epoch 27/200\n",
      "320/320 [==============================] - 0s 803us/step - loss: 0.1417 - accuracy: 0.9462\n",
      "Epoch 28/200\n",
      "320/320 [==============================] - 0s 812us/step - loss: 0.1352 - accuracy: 0.9480\n",
      "Epoch 29/200\n",
      "320/320 [==============================] - 0s 794us/step - loss: 0.1359 - accuracy: 0.9466\n",
      "Epoch 30/200\n",
      "320/320 [==============================] - 0s 825us/step - loss: 0.1344 - accuracy: 0.9477\n",
      "Epoch 31/200\n",
      "320/320 [==============================] - 0s 794us/step - loss: 0.1318 - accuracy: 0.9469\n",
      "Epoch 32/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.1282 - accuracy: 0.9520\n",
      "Epoch 33/200\n",
      "320/320 [==============================] - 0s 728us/step - loss: 0.1266 - accuracy: 0.9505\n",
      "Epoch 34/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.1252 - accuracy: 0.9535\n",
      "Epoch 35/200\n",
      "320/320 [==============================] - 0s 781us/step - loss: 0.1234 - accuracy: 0.9512\n",
      "Epoch 36/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.1224 - accuracy: 0.9526\n",
      "Epoch 37/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.1227 - accuracy: 0.9519\n",
      "Epoch 38/200\n",
      "320/320 [==============================] - 0s 759us/step - loss: 0.1240 - accuracy: 0.9517\n",
      "Epoch 39/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.1184 - accuracy: 0.9540\n",
      "Epoch 40/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.1156 - accuracy: 0.9550\n",
      "Epoch 41/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.1168 - accuracy: 0.9548\n",
      "Epoch 42/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.1141 - accuracy: 0.9574\n",
      "Epoch 43/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.1128 - accuracy: 0.9560\n",
      "Epoch 44/200\n",
      "320/320 [==============================] - 0s 753us/step - loss: 0.1109 - accuracy: 0.9582\n",
      "Epoch 45/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.1097 - accuracy: 0.9569\n",
      "Epoch 46/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.1100 - accuracy: 0.9562\n",
      "Epoch 47/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.1088 - accuracy: 0.9575\n",
      "Epoch 48/200\n",
      "320/320 [==============================] - 0s 757us/step - loss: 0.1078 - accuracy: 0.9587\n",
      "Epoch 49/200\n",
      "320/320 [==============================] - 0s 803us/step - loss: 0.1049 - accuracy: 0.9592\n",
      "Epoch 50/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.1065 - accuracy: 0.9570\n",
      "Epoch 51/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.1037 - accuracy: 0.9585\n",
      "Epoch 52/200\n",
      "320/320 [==============================] - 0s 774us/step - loss: 0.1042 - accuracy: 0.9598\n",
      "Epoch 53/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.1007 - accuracy: 0.9617\n",
      "Epoch 54/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.1046 - accuracy: 0.9575\n",
      "Epoch 55/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0996 - accuracy: 0.9595\n",
      "Epoch 56/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0991 - accuracy: 0.9588\n",
      "Epoch 57/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0970 - accuracy: 0.9622\n",
      "Epoch 58/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0989 - accuracy: 0.9591\n",
      "Epoch 59/200\n",
      "320/320 [==============================] - 0s 741us/step - loss: 0.0949 - accuracy: 0.9626\n",
      "Epoch 60/200\n",
      "320/320 [==============================] - 0s 787us/step - loss: 0.0959 - accuracy: 0.9617\n",
      "Epoch 61/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0953 - accuracy: 0.9613\n",
      "Epoch 62/200\n",
      "320/320 [==============================] - 0s 756us/step - loss: 0.0936 - accuracy: 0.9617\n",
      "Epoch 63/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0928 - accuracy: 0.9643\n",
      "Epoch 64/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0911 - accuracy: 0.9634\n",
      "Epoch 65/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0910 - accuracy: 0.9630\n",
      "Epoch 66/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0922 - accuracy: 0.9628\n",
      "Epoch 67/200\n",
      "320/320 [==============================] - 0s 753us/step - loss: 0.0905 - accuracy: 0.9627\n",
      "Epoch 68/200\n",
      "320/320 [==============================] - 0s 756us/step - loss: 0.0911 - accuracy: 0.9631\n",
      "Epoch 69/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0886 - accuracy: 0.9640\n",
      "Epoch 70/200\n",
      "320/320 [==============================] - 0s 744us/step - loss: 0.0895 - accuracy: 0.9626\n",
      "Epoch 71/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0866 - accuracy: 0.9658\n",
      "Epoch 72/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0846 - accuracy: 0.9663\n",
      "Epoch 73/200\n",
      "320/320 [==============================] - 0s 756us/step - loss: 0.0862 - accuracy: 0.9654\n",
      "Epoch 74/200\n",
      "320/320 [==============================] - 0s 753us/step - loss: 0.0842 - accuracy: 0.9671\n",
      "Epoch 75/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0835 - accuracy: 0.9671\n",
      "Epoch 76/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0831 - accuracy: 0.9674\n",
      "Epoch 77/200\n",
      "320/320 [==============================] - 0s 738us/step - loss: 0.0822 - accuracy: 0.9664\n",
      "Epoch 78/200\n",
      "320/320 [==============================] - 0s 790us/step - loss: 0.0800 - accuracy: 0.9684\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 743us/step - loss: 0.0873 - accuracy: 0.9644\n",
      "Epoch 80/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0812 - accuracy: 0.9665\n",
      "Epoch 81/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0786 - accuracy: 0.9701\n",
      "Epoch 82/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0775 - accuracy: 0.9684\n",
      "Epoch 83/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0765 - accuracy: 0.9699\n",
      "Epoch 84/200\n",
      "320/320 [==============================] - 0s 718us/step - loss: 0.0779 - accuracy: 0.9674\n",
      "Epoch 85/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0773 - accuracy: 0.9712\n",
      "Epoch 86/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0754 - accuracy: 0.9691\n",
      "Epoch 87/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0758 - accuracy: 0.9691\n",
      "Epoch 88/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0767 - accuracy: 0.9671\n",
      "Epoch 89/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0744 - accuracy: 0.9713\n",
      "Epoch 90/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0717 - accuracy: 0.9703\n",
      "Epoch 91/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0729 - accuracy: 0.9717\n",
      "Epoch 92/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0717 - accuracy: 0.9718\n",
      "Epoch 93/200\n",
      "320/320 [==============================] - 0s 718us/step - loss: 0.0716 - accuracy: 0.9701\n",
      "Epoch 94/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0713 - accuracy: 0.9722\n",
      "Epoch 95/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0698 - accuracy: 0.9699\n",
      "Epoch 96/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.0765 - accuracy: 0.9680\n",
      "Epoch 97/200\n",
      "320/320 [==============================] - 0s 725us/step - loss: 0.0691 - accuracy: 0.9733\n",
      "Epoch 98/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0677 - accuracy: 0.9735\n",
      "Epoch 99/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0677 - accuracy: 0.9725\n",
      "Epoch 100/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0680 - accuracy: 0.97130s - loss: 0.0661 - accuracy: \n",
      "Epoch 101/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0685 - accuracy: 0.9722\n",
      "Epoch 102/200\n",
      "320/320 [==============================] - 0s 744us/step - loss: 0.0640 - accuracy: 0.9748\n",
      "Epoch 103/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0701 - accuracy: 0.9714\n",
      "Epoch 104/200\n",
      "320/320 [==============================] - 0s 744us/step - loss: 0.0643 - accuracy: 0.9736\n",
      "Epoch 105/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0615 - accuracy: 0.9764\n",
      "Epoch 106/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0625 - accuracy: 0.9749\n",
      "Epoch 107/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0650 - accuracy: 0.9743\n",
      "Epoch 108/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0644 - accuracy: 0.9736\n",
      "Epoch 109/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0640 - accuracy: 0.9743\n",
      "Epoch 110/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.0614 - accuracy: 0.9749\n",
      "Epoch 111/200\n",
      "320/320 [==============================] - 0s 735us/step - loss: 0.0628 - accuracy: 0.9748\n",
      "Epoch 112/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0626 - accuracy: 0.9756\n",
      "Epoch 113/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0593 - accuracy: 0.9767\n",
      "Epoch 114/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0603 - accuracy: 0.9765\n",
      "Epoch 115/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0573 - accuracy: 0.9768\n",
      "Epoch 116/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0571 - accuracy: 0.9765\n",
      "Epoch 117/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0581 - accuracy: 0.9766\n",
      "Epoch 118/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0602 - accuracy: 0.9761\n",
      "Epoch 119/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0546 - accuracy: 0.9786\n",
      "Epoch 120/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0574 - accuracy: 0.9763\n",
      "Epoch 121/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0560 - accuracy: 0.9782\n",
      "Epoch 122/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0558 - accuracy: 0.9766\n",
      "Epoch 123/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0638 - accuracy: 0.9737\n",
      "Epoch 124/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0603 - accuracy: 0.9767\n",
      "Epoch 125/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0525 - accuracy: 0.9793\n",
      "Epoch 126/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0531 - accuracy: 0.9803\n",
      "Epoch 127/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0518 - accuracy: 0.9788\n",
      "Epoch 128/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0540 - accuracy: 0.9771\n",
      "Epoch 129/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0579 - accuracy: 0.9763\n",
      "Epoch 130/200\n",
      "320/320 [==============================] - 0s 718us/step - loss: 0.0519 - accuracy: 0.9791\n",
      "Epoch 131/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0507 - accuracy: 0.9812\n",
      "Epoch 132/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0531 - accuracy: 0.9780\n",
      "Epoch 133/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0515 - accuracy: 0.9786\n",
      "Epoch 134/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0508 - accuracy: 0.9800\n",
      "Epoch 135/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0482 - accuracy: 0.9808\n",
      "Epoch 136/200\n",
      "320/320 [==============================] - 0s 725us/step - loss: 0.0502 - accuracy: 0.9797\n",
      "Epoch 137/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.0491 - accuracy: 0.9819\n",
      "Epoch 138/200\n",
      "320/320 [==============================] - 0s 812us/step - loss: 0.0492 - accuracy: 0.9796\n",
      "Epoch 139/200\n",
      "320/320 [==============================] - 0s 775us/step - loss: 0.0487 - accuracy: 0.9806\n",
      "Epoch 140/200\n",
      "320/320 [==============================] - 0s 769us/step - loss: 0.0469 - accuracy: 0.9824\n",
      "Epoch 141/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0504 - accuracy: 0.9800\n",
      "Epoch 142/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0501 - accuracy: 0.9804\n",
      "Epoch 143/200\n",
      "320/320 [==============================] - 0s 781us/step - loss: 0.0453 - accuracy: 0.9821\n",
      "Epoch 144/200\n",
      "320/320 [==============================] - 0s 801us/step - loss: 0.0461 - accuracy: 0.9812\n",
      "Epoch 145/200\n",
      "320/320 [==============================] - 0s 875us/step - loss: 0.0464 - accuracy: 0.9829\n",
      "Epoch 146/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0462 - accuracy: 0.9825\n",
      "Epoch 147/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0469 - accuracy: 0.9825\n",
      "Epoch 148/200\n",
      "320/320 [==============================] - 0s 732us/step - loss: 0.0407 - accuracy: 0.9845\n",
      "Epoch 149/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0438 - accuracy: 0.9834\n",
      "Epoch 150/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0483 - accuracy: 0.9802\n",
      "Epoch 151/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0452 - accuracy: 0.9828\n",
      "Epoch 152/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0428 - accuracy: 0.9836\n",
      "Epoch 153/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0450 - accuracy: 0.9829\n",
      "Epoch 154/200\n",
      "320/320 [==============================] - 0s 750us/step - loss: 0.0569 - accuracy: 0.9775\n",
      "Epoch 155/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0388 - accuracy: 0.9858\n",
      "Epoch 156/200\n",
      "320/320 [==============================] - 0s 725us/step - loss: 0.0410 - accuracy: 0.9837\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320/320 [==============================] - 0s 724us/step - loss: 0.0381 - accuracy: 0.9849\n",
      "Epoch 158/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0429 - accuracy: 0.9839\n",
      "Epoch 159/200\n",
      "320/320 [==============================] - 0s 749us/step - loss: 0.0391 - accuracy: 0.9847\n",
      "Epoch 160/200\n",
      "320/320 [==============================] - 0s 746us/step - loss: 0.0421 - accuracy: 0.9844\n",
      "Epoch 161/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0396 - accuracy: 0.9853\n",
      "Epoch 162/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0381 - accuracy: 0.9863\n",
      "Epoch 163/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0428 - accuracy: 0.9833\n",
      "Epoch 164/200\n",
      "320/320 [==============================] - 0s 719us/step - loss: 0.0384 - accuracy: 0.9859\n",
      "Epoch 165/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0426 - accuracy: 0.9840\n",
      "Epoch 166/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0471 - accuracy: 0.9834\n",
      "Epoch 167/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0366 - accuracy: 0.9852\n",
      "Epoch 168/200\n",
      "320/320 [==============================] - 0s 731us/step - loss: 0.0448 - accuracy: 0.98240s - loss: 0.0639 - accuracy\n",
      "Epoch 169/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0357 - accuracy: 0.9861\n",
      "Epoch 170/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0376 - accuracy: 0.9849\n",
      "Epoch 171/200\n",
      "320/320 [==============================] - 0s 715us/step - loss: 0.0358 - accuracy: 0.9875\n",
      "Epoch 172/200\n",
      "320/320 [==============================] - 0s 718us/step - loss: 0.0370 - accuracy: 0.9858\n",
      "Epoch 173/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0360 - accuracy: 0.9873\n",
      "Epoch 174/200\n",
      "320/320 [==============================] - 0s 724us/step - loss: 0.0359 - accuracy: 0.9871\n",
      "Epoch 175/200\n",
      "320/320 [==============================] - 0s 728us/step - loss: 0.0338 - accuracy: 0.9874\n",
      "Epoch 176/200\n",
      "320/320 [==============================] - 0s 768us/step - loss: 0.0362 - accuracy: 0.9863\n",
      "Epoch 177/200\n",
      "320/320 [==============================] - 0s 753us/step - loss: 0.0392 - accuracy: 0.9847\n",
      "Epoch 178/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0331 - accuracy: 0.9880\n",
      "Epoch 179/200\n",
      "320/320 [==============================] - 0s 721us/step - loss: 0.0335 - accuracy: 0.9874\n",
      "Epoch 180/200\n",
      "320/320 [==============================] - 0s 734us/step - loss: 0.0375 - accuracy: 0.9864\n",
      "Epoch 181/200\n",
      "320/320 [==============================] - 0s 772us/step - loss: 0.0473 - accuracy: 0.9839\n",
      "Epoch 182/200\n",
      "320/320 [==============================] - 0s 771us/step - loss: 0.0307 - accuracy: 0.9893\n",
      "Epoch 183/200\n",
      "320/320 [==============================] - 0s 771us/step - loss: 0.0372 - accuracy: 0.9864\n",
      "Epoch 184/200\n",
      "320/320 [==============================] - 0s 740us/step - loss: 0.0324 - accuracy: 0.9882\n",
      "Epoch 185/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0318 - accuracy: 0.9893\n",
      "Epoch 186/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0306 - accuracy: 0.9882\n",
      "Epoch 187/200\n",
      "320/320 [==============================] - 0s 744us/step - loss: 0.0399 - accuracy: 0.9851\n",
      "Epoch 188/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0357 - accuracy: 0.9858\n",
      "Epoch 189/200\n",
      "320/320 [==============================] - 0s 737us/step - loss: 0.0272 - accuracy: 0.9904\n",
      "Epoch 190/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0384 - accuracy: 0.9861\n",
      "Epoch 191/200\n",
      "320/320 [==============================] - 0s 762us/step - loss: 0.0386 - accuracy: 0.9848\n",
      "Epoch 192/200\n",
      "320/320 [==============================] - 0s 778us/step - loss: 0.0347 - accuracy: 0.9881\n",
      "Epoch 193/200\n",
      "320/320 [==============================] - 0s 759us/step - loss: 0.0273 - accuracy: 0.9910\n",
      "Epoch 194/200\n",
      "320/320 [==============================] - 0s 772us/step - loss: 0.0281 - accuracy: 0.9890\n",
      "Epoch 195/200\n",
      "320/320 [==============================] - 0s 759us/step - loss: 0.0289 - accuracy: 0.9895\n",
      "Epoch 196/200\n",
      "320/320 [==============================] - 0s 743us/step - loss: 0.0352 - accuracy: 0.9874\n",
      "Epoch 197/200\n",
      "320/320 [==============================] - 0s 727us/step - loss: 0.0311 - accuracy: 0.9884\n",
      "Epoch 198/200\n",
      "320/320 [==============================] - 0s 772us/step - loss: 0.0277 - accuracy: 0.9914\n",
      "Epoch 199/200\n",
      "320/320 [==============================] - 0s 771us/step - loss: 0.0280 - accuracy: 0.9892\n",
      "Epoch 200/200\n",
      "320/320 [==============================] - 0s 747us/step - loss: 0.0306 - accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25faac57220>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_model.fit(x_train, y_train, batch_size = 32, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc_cnn = CNN_model.evaluate(x_train, y_train, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885406494140625\n"
     ]
    }
   ],
   "source": [
    "print(acc_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = CNN_model.predict(x_test)\n",
    "y_pred[y_pred <= 0.5] = 0\n",
    "y_pred[y_pred > 0.5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY COMPARISON OF ALL THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [acc_lr * 100,\n",
    "          acc_knn * 100,\n",
    "          acc_svm * 100,\n",
    "          acc_nb * 100,\n",
    "          acc_dt * 100,\n",
    "          acc_rf * 100,\n",
    "          acc_cnn * 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Logistic Regression\",\n",
    "        \"K-Nearest Neighbors\",\n",
    "        \"Support Vector Machine\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Decision Tree\",\n",
    "        \"Random Forest\",\n",
    "        \"Convolutional Neural Network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Algorithm Name'] = names\n",
    "df['Accuracy Score (%)'] = scores\n",
    "df = df.sort_values('Accuracy Score (%)', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm Name</th>\n",
       "      <th>Accuracy Score (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Convolutional Neural Network</td>\n",
       "      <td>98.854065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>97.280799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>96.725860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>86.570477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>84.961154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>84.850166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>84.794673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Algorithm Name  Accuracy Score (%)\n",
       "6  Convolutional Neural Network           98.854065\n",
       "5                 Random Forest           97.280799\n",
       "4                 Decision Tree           96.725860\n",
       "1           K-Nearest Neighbors           86.570477\n",
       "3                   Naive Bayes           84.961154\n",
       "0           Logistic Regression           84.850166\n",
       "2        Support Vector Machine           84.794673"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.subplots(figsize = (10, 5))\n",
    "ax = sns.barplot(x = \"Accuracy Score (%)\", y = \"Algorithm Name\", data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE BEST TRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('../model/project_model.h5') is False:\n",
    "    CNN_model.save('../model/project_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
